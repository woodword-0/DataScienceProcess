M3L1

# Import the necessary libraries
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense



# Example text data
texts = ['Hello, how are you?', 'I am doing great!', 'What about you?']

# Tokenization
tokenizer = Tokenizer()
tokenizer.fit_on_texts(texts)
sequences = tokenizer.texts_to_sequences(texts)

# Padding
max_len = max(len(sequence) for sequence in sequences)
padded_sequences = pad_sequences(sequences, maxlen=max_len)

print(padded_sequences)



# Define the model
model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_len))
model.add(LSTM(128))
model.add(Dense(1, activation='sigmoid'))




# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])



# Train the model
labels = np.array([0, 1, 0], dtype=np.float32)  # Example binary labels
labels = np.reshape(labels, (-1, 1))  # Reshape to match the model's output shape

model.fit(padded_sequences, labels, epochs=10, batch_size=1)



# Example test data
test_data = ['How are you doing today?']

# Preprocess test data
test_sequences = tokenizer.texts_to_sequences(test_data)
test_padded_sequences = pad_sequences(test_sequences, maxlen=max_len)

# Make predictions
predictions = model.predict(test_padded_sequences)
print(predictions)







