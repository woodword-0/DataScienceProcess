{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Long Sequences and Overfitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Long Sequences\n",
    "2. Techniques for Handling Long Sequences\n",
    "3. Strategies to Mitigate Overfitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Sequences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In machine learning (ML), long sequences refer to input or output sequences that are relatively large or have a large number of elements. The length of a sequence can vary depending on the specific problem and dataset. Long sequences can be encountered in various ML tasks, including natural language processing (NLP), speech recognition, time series analysis, and more"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. During backpropagation, gradients are computed to update the model's parameters.\n",
    "2. In long sequences, the gradients may become exponentially small or large \n",
    "3. Gradients may vanish or explode (approach infinity), stopping learning process.\n",
    "4. Prevents the model from effectively capturing long-term dependencies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techniques for Handling Long Sequences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sequence truncation: Cutting off all values of the sequence after a certain length so \n",
    "that all sequences are the same length"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Sequence padding: Making all sequences zero (or some other constant after a certain length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Batching: taking batches of sequences (say 32 at a time) rather than all data in batches (tricky for time series)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Keeping all lengths of sequences and binning them by length adding a classification component to the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Dynamic length handling: Built in techniques for Tensorflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting is a phenomenon that occurs in machine learning when a model learns to perform extremely well on the training data but fails to generalize well to unseen or new data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies to Mitigate Overfitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Regularization Techniques: L1 and L2 regularization: Adding a squared sum to add a score to incorrect predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Dropout: Drops out of training when validation scores drop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Training and Evaluation:splitting the dataset into training, validation, and test sets for model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TfIntm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
