{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Data Preparation for Time Series Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Preprocessing Techniques\n",
    "1. Missing Values\n",
    "2. Dealing with outliers\n",
    "3. Resampling for forecasting\n",
    "4. Scaling and Normalization\n",
    "5. Seasonality and Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Import the necessary libraries\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series index\n",
    "\n",
    "start = pd.to_datetime('2023-01-01 00:00:00')\n",
    "\n",
    "timestamps = pd.date_range(start, periods=100, freq='15T')\n",
    "\n",
    "dates = pd.to_datetime(timestamps)\n",
    "\n",
    "# Create a time series with random values\n",
    "\n",
    "values = np.random.rand(len(dates))\n",
    "\n",
    "# Create a DataFrame with the time index and values\n",
    "\n",
    "time_series = pd.DataFrame({'Value': values}, index=dates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fill missing values with forward fill (last known value)\n",
    "\n",
    "data_filled = time_series.ffill()\n",
    "\n",
    "# Fill missing values with backward fill (next known value)\n",
    "\n",
    "data_filled = time_series.bfill()\n",
    "\n",
    "# Fill missing values with interpolation\n",
    "\n",
    "data_filled = time_series.interpolate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compute z-scores for each data point\n",
    "\n",
    "z_scores = np.abs(stats.zscore(time_series))\n",
    "\n",
    "# Define a threshold for outlier detection\n",
    "\n",
    "threshold = 3\n",
    "\n",
    "# Identify outlier indices\n",
    "\n",
    "outlier_indices = np.where(z_scores > threshold)[0]\n",
    "\n",
    "# Remove outliers\n",
    "\n",
    "data_no_outliers = time_series.copy()\n",
    "\n",
    "data_no_outliers.iloc[outlier_indices] = np.nan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling for Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to a higher frequency (e.g., from daily to hourly)\n",
    "\n",
    "data_resampled = time_series.resample('H').mean()\n",
    "\n",
    "# Resample to a lower frequency (e.g., from daily to monthly)\n",
    "\n",
    "data_resampled = time_series.resample('M').sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max scaling\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data_scaled = scaler.fit_transform(time_series)\n",
    "\n",
    "# Standardization\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "data_standardized = scaler.fit_transform(time_series)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonality and Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose the time series into trend, seasonal, and residual components\n",
    "\n",
    "decomposition = seasonal_decompose(time_series)\n",
    "# Access the individual components\n",
    "\n",
    "trend = decomposition.trend\n",
    "\n",
    "seasonal = decomposition.seasonal\n",
    "\n",
    "residual = decomposition.resid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TfIntm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
