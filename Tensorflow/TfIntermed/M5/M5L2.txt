M5L2

import tensorflow as tf
# Save the model
# model.save('my_model.h5')

# Load the TensorFlow model
model = tf.keras.models.load_model('my_model.h5')
# Convert the model to TensorFlow Lite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
# Save the converted model
with open('my_model.tflite', 'wb') as f:
    f.write(tflite_model)

# Apply post-training quantization
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()


# Load the TensorFlow Lite model
interpreter = tf.lite.Interpreter(model_path='my_model.tflite')
interpreter.allocate_tensors()
# Get input and output details
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Perform inference
input_data = ...  # Prepare your input data
interpreter.set_tensor(input_details[0]['index'], input_data)
interpreter.invoke()
output_data = interpreter.get_tensor(output_details[0]['index'])
